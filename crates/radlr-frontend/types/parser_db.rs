use super::{grammar_object_ids::GrammarIdentities, rule::Rule, *};
use crate::{array_vec::ArrayVec, grammar_db_compiler::ASTToken, types::item::*};
use radlr_core_common::{CachedString, OrderedMap, OrderedSet};
use radlr_rust_runtime::types::TokenRange;
use std::{collections::VecDeque, sync::Arc};

pub type SharedParserDatabase = std::sync::Arc<ParserDatabase>;

/// The internal data type used for the compilation and analysis of grammars and
/// parsers. contains additional metadata for compilation of LLVM and Bytecode
/// parsers.
#[derive(Clone, Default, Debug)]
pub struct ParserDatabase {
  pub root_grammar_id:      GrammarIdentities,
  /// Maps a non-terminal to all other non-terminals that reference it, directly
  /// or indirectly,  within their rules.
  pub nonterm_predecessors: OrderedMap<DBNonTermKey, OrderedSet<DBNonTermKey>>,

  pub nonterm_ids: Vec<NonTermId>,

  /// Maps a non-terminal to all rules that contain the nonterm's symbol in
  /// their bodies.
  pub nonterm_symbol_to_rules: OrderedMap<DBNonTermKey, OrderedSet<DBRuleKey>>,
  /// Table mapping non-terminal indices to rule indices.
  pub nonterm_rules:           Vec<Vec<DBRuleKey>>,
  /// Table of all rules within the grammar and the non-terminal they reduce
  /// to.
  pub rules:                   Vec<Rule>,
  /// Table of all tokens generated by the scanners.
  pub tokens:                  Vec<DBTokenData>,
  /// The entry point non-terminals of the grammar.
  pub entry_points:            Vec<DBEntryPoint>,
  /// Custom states that should be integrated into the final parsers
  //custom_states:           Vec<Option<Box<parser::State>>>,
  /// True if the database represents a valid set of rules. This may not be
  /// the case if, for example, the database is comprised of rules that
  /// reference non-extant non-terminals.
  pub valid:                   bool,
  /// items

  /// All items that follow a non-terminal
  pub follow_items:            Vec<Vec<ItemIndex>>,
  /// Item closures, stores the closure of all items, excluding the closure's of
  /// items that are complete.
  pub item_closures:           Vec<Vec<ArrayVec<4, Item>>>,
  ///NonTerminal Recursion Type
  pub recursion_types:         Vec<u8>,
  /// Reduction types
  pub reduction_types:         Vec<ReductionType>,
  /// Sets of skipped symbols
  pub skip_sets:               Vec<OrderedSet<SymbolId>>,
}

impl AsRef<[Rule]> for ParserDatabase {
  fn as_ref(&self) -> &[Rule] {
    self.rules()
  }
}

impl ParserDatabase {
  /// Prints token ids and their friendly names to the console
  pub fn print_tokens(&self) {
    let token_strings = self.tokens.iter().enumerate().map(|(idx, t)| format!("{:>0000}: {}", idx, t.name.to_str().as_str()));

    println!("{}", token_strings.collect::<Vec<_>>().join("\n"))
  }

  pub fn is_valid(&self) -> bool {
    self.valid
  }

  /// Returns an array of [DBNonTermKey]s of the entry point non-terminals.
  pub fn entry_nterm_keys(&self) -> Vec<DBNonTermKey> {
    self.entry_points.iter().map(|k| k.nonterm_key).collect()
  }

  /// Returns an array of [DBNonTermKey]s of the entry point non-terminals.
  pub fn entry_nterm_map(&self) -> OrderedMap<DBNonTermKey, &DBEntryPoint> {
    self.entry_points.iter().map(|k| (k.nonterm_key, k)).collect()
  }

  /// Returns an array of [EntryPoint]s of the entry point non-terminals.
  pub fn entry_points(&self) -> Vec<&DBEntryPoint> {
    self.entry_points.iter().map(|k| k).collect()
  }

  /// Returns the number of non-terminals stored in the DB
  pub fn nonterms_len(&self) -> usize {
    self.nonterm_ids.len()
  }

  /// Returns an ordered array of all non-terminals within the DB
  pub fn nonterms(&self) -> &Vec<NonTermId> {
    &self.nonterm_ids
  }

  /// Returns a map from a nonterm key to rules that have the matching nonterm
  /// symbol in their bodies.
  pub fn get_nonterm_symbol_to_rules(&self) -> &OrderedMap<DBNonTermKey, OrderedSet<DBRuleKey>> {
    &self.nonterm_symbol_to_rules
  }

  /// Returns an ordered array of all non-terminals within the DB
  pub fn get_nonterminal_predecessors(&self, key: DBNonTermKey) -> Option<&OrderedSet<DBNonTermKey>> {
    self.nonterm_predecessors.get(&key)
  }

  /// Given a [DBNonTermKey] returns the SymbolId representing the non-terminal,
  /// or [SymbolId::Undefined] if the id is invalid.
  pub fn nonterm_from_name(&self, name: &str) -> DBNonTermKey {
    let string = name.to_token();
    self
      .nonterm_ids
      .iter()
      .find_map(|id| if id.friendly_name == string || id.uu_name == string { Some(id.db_key) } else { None })
      .unwrap_or_default()
  }

  /// Returns the guid name of the database as a string.
  pub fn name_string(&self) -> String {
    self.root_grammar_id.guid_name.to_string()
  }

  pub fn friendly_name_string(&self) -> String {
    self.root_grammar_id.local_name.to_string()
  }

  /// Given a [DBNonTermKey] returns the SymbolId representing the non-terminal,
  /// or [SymbolId::Undefined] if the id is invalid.
  pub fn nonterm_sym(&self, key: DBNonTermKey) -> SymbolId {
    debug_assert!((key.0 as usize) < self.nonterm_ids.len(), "Invalid DBNonTermKey received");
    self.nonterm_ids[key.0 as usize].sym
  }

  /// Given a [DBNonTermKey] returns an IString comprising the name of the
  /// non-terminal, or an empty string if the id is invalid.
  pub fn nonterm_guid_name(&self, key: DBNonTermKey) -> IString {
    self.nonterm_ids.get(key.0 as usize).map(|id| id.uu_name).unwrap_or_default()
  }

  /// Given a [DBNonTermKey] returns a [GuardedStr] of the non-terminal's name.
  /// Returns an empty string if the key is invalid.
  pub fn nonterm_guid_name_string<'a>(&'a self, key: DBNonTermKey) -> String {
    self.nonterm_guid_name(key).to_string()
  }

  /// Given a [DBNonTermKey] returns an IString comprising the name of the
  /// non-terminal, or an empty string if the id is invalid.
  pub fn nonterm_friendly_name(&self, key: DBNonTermKey) -> IString {
    self.nonterm_ids.get(key.0 as usize).map(|id| id.friendly_name).unwrap_or_default()
  }

  /// Given a [DBNonTermKey] returns a [GuardedStr] of the non-terminal's name.
  /// Returns an empty string if the key is invalid.
  pub fn nonterm_friendly_name_string<'a>(&'a self, key: DBNonTermKey) -> String {
    self.nonterm_friendly_name(key).to_string()
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn token(&self, key: DBTermKey) -> DBTokenData {
    debug_assert!((key.0 as usize) < self.tokens.len(), "Invalid DBSymKey received");
    self.tokens[key.0 as usize]
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tokens(&self) -> &Vec<DBTokenData> {
    &self.tokens
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tok_val(&self, key: DBTermKey) -> usize {
    #[cfg(debug_assertions)]
    {
      let val = self.token(key).tok_id.0 as usize;
      debug_assert!((key.0 as usize) == val);
      val
    }
    #[cfg(not(debug_assertions))]
    {
      key.0 as usize
    }
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tok_data(&self, key: DBTermKey) -> &DBTokenData {
    self.tokens.get(key.0 as usize).as_ref().unwrap()
  }

  /// Given a [DBTermKey] returns the [DBNonTermKey] representing the scanner
  /// nonterminal for the symbol, or None
  pub fn tok_prod(&self, key: DBTermKey) -> Option<DBNonTermKey> {
    self.tokens.get(key.0 as usize).map(|s| s.nonterm_id)
  }

  /// Given a [DBTermKey] returns the associated [SymbolId]
  pub fn sym(&self, key: DBTermKey) -> SymbolId {
    self.tokens.get(key.0 as usize).map(|s| s.sym_id).unwrap_or_default()
  }

  /// Given a nonterm [DBNonTermKey] returns an [Vec] of [DBRuleKey]s
  /// belonging to rules that reduce to that nonterm, or `None` if the id is
  /// invalid.
  pub fn nonterm_producing_rules(&self, key: DBNonTermKey) -> Option<&Vec<DBRuleKey>> {
    self.nonterm_rules.get(key.0 as usize)
  }

  /// Returns the internal Rules
  pub fn rules(&self) -> &[Rule] {
    self.rules.as_slice()
  }

  /// Given a [DBRuleKey] returns an [Rule], or `None` if
  /// the id is invalid.
  pub fn rule(&self, key: DBRuleKey) -> &Rule {
    if cfg!(debug_assertions) {
      self.rules.get(key.0 as usize).unwrap()
    } else {
      unsafe { self.rules.get(key.0 as usize).unwrap_unchecked() }
    }
  }

  /// Given a [DBRuleKey] returns an [Rule], or `None` if
  /// the id is invalid.
  pub fn db_rule(&self, key: DBRuleKey) -> &Rule {
    if cfg!(debug_assertions) {
      self.rules.get(key.0 as usize).unwrap()
    } else {
      unsafe { self.rules.get(key.0 as usize).unwrap_unchecked() }
    }
  }

  /// Given a [DBRuleKey] returns an [Rule], or `None` if
  /// the id is invalid.
  /*   pub fn custom_state(&self, key: DBNonTermKey) -> Option<&parser::State> {
    if cfg!(debug_assertions) {
      self.custom_states.get(key.0 as usize).unwrap().as_deref()
    } else {
      unsafe { self.custom_states.get(key.0 as usize).unwrap_unchecked().as_deref() }
    }
  } */

  /// Given a [DBRuleKey] returns the [DBNonTermKey] the rule reduces to.
  pub fn rule_nonterm(&self, key: DBRuleKey) -> DBNonTermKey {
    self.rules.get(key.0 as usize).map(|e| e.nonterm_id).unwrap_or_default()
  }

  /// Returns a reference to the [IStringStore]
  pub fn get_reduce_type(&self, rule_id: DBRuleKey) -> ReductionType {
    self.reduction_types[rule_id.0 as usize]
  }

  pub fn nonterm_recursion_type(&self, nonterm: DBNonTermKey) -> RecursionType {
    match self.recursion_types[nonterm.0 as usize] {
      3 => RecursionType::LeftRightRecursive,
      2 => RecursionType::RightRecursive,
      1 => RecursionType::LeftRecursive,
      _ => RecursionType::None,
    }
  }

  /// Returns the closure of the item.
  /// > note: The closure does not include the item used as the seed for the
  /// > closure.
  #[inline]
  pub fn get_closure<'db>(&'db self, item: &Item) -> &[Item] {
    let item = *item;
    &self.item_closures[item.rule_id().0 as usize][item.sym_index() as usize].as_slice()
  }

  /// Returns all regular (non token) nonterminals.
  pub fn parser_nonterms(&self) -> Vec<DBNonTermKey> {
    self
      .nonterms()
      .iter()
      .filter_map(|p| match !p.is_terminal {
        true => Some(p.db_key),
        _ => None,
      })
      .collect()
  }

  /// Returns an iterator of all items that are `_ = ...•Aa`  for some
  /// [DBNonTermKey] `A`, or in other words this returns the list of items that
  /// would shift over the [DBNonTermKey] `A`. If an item is `B = ...•A`, then
  /// this also returns items that are `_ = ...•Ba`
  pub fn nonterm_follow_items<'db>(&'db self, nonterm: DBNonTermKey) -> impl Iterator<Item = Item> + Clone + 'db {
    self.follow_items[nonterm.0 as usize].iter().map(move |i| Item::from((*i, self.as_ref())))
  }
}

macro_rules! indexed_id_implementations {
  ($id_type:ty) => {
    impl $id_type {
      pub fn to_string(&self) -> String {
        self.0.to_string()
      }
    }

    impl From<u32> for $id_type {
      fn from(value: u32) -> Self {
        Self(value)
      }
    }

    impl From<usize> for $id_type {
      fn from(value: usize) -> Self {
        Self(value as u32)
      }
    }

    impl Into<usize> for $id_type {
      fn into(self) -> usize {
        self.0 as usize
      }
    }

    impl Into<u32> for $id_type {
      fn into(self) -> u32 {
        self.0 as u32
      }
    }

    impl Default for $id_type {
      fn default() -> Self {
        Self(u32::MAX)
      }
    }
  };
}

#[derive(Default, Clone, Copy, Debug)]
pub enum ReductionType {
  /// Any reduction resulting in the execution of a some kind of semantic
  /// action. At this point only `:ast` semantic actions are available.
  SemanticAction,
  /// A reduction of a terminal symbol to a nonterminal
  SingleTerminal,
  /// A reduction of single nonterminal symbol to another nonterminal
  SingleNonTerminal,
  /// A reduction of a left-recursive rule
  LeftRecursive,
  #[default]
  /// A reduction of more than one symbol to a nonterminal
  Mixed,
}

// The type of recursion that can occur for a given rule.
#[derive(Default, Clone, Copy, Debug)]
pub enum RecursionType {
  #[default]
  None               = 0,
  LeftRecursive      = 1,
  RightRecursive     = 2,
  LeftRightRecursive = 3,
}

impl RecursionType {
  #[inline]
  pub fn is_recursive(&self) -> bool {
    self.is_left_recursive() || self.is_right_recursive()
  }

  #[inline]
  pub fn is_left_recursive(&self) -> bool {
    matches!(self, Self::LeftRecursive | Self::LeftRightRecursive)
  }

  #[inline]
  pub fn is_right_recursive(&self) -> bool {
    matches!(self, Self::RightRecursive | Self::LeftRightRecursive)
  }
}

#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Debug)]
pub struct DBTokenData {
  /// The symbol type and precedence.
  pub sym_id:     SymbolId,
  /// The friendly name of this token.
  pub name:       IString,
  /// The scanner non-terminal id of this token.
  pub nonterm_id: DBNonTermKey,
  /// The id of the symbol when used as a lexer token.
  pub tok_id:     DBTermKey,
}

#[derive(Clone, Copy, Debug)]
pub struct DBEntryPoint {
  pub nonterm_key:        DBNonTermKey,
  /// The GUID name of the non-terminal.
  pub nonterm_name:       IString,
  /// The GUID name of the non-terminal's entry state.
  pub nonterm_entry_name: IString,
  /// The GUID name of the non-terminal's exit state.
  pub nonterm_exit_name:  IString,
  /// The friendly name of the non-terminal as specified in the
  /// `IMPORT <nonterm> as <entry_name>` preamble.
  pub entry_name:         IString,
  ///
  pub export_id:          usize,
  /// `true` if the entry point was defined through an `ENTRY` clause
  pub is_export:          bool,
}
