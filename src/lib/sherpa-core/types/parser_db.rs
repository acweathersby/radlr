use super::{o_to_r, Array, IString, IStringStore, Item, Items, Rule, Set, SymbolId, SymbolRef};
use crate::{parser, CachedString, SherpaResult};
use std::collections::{HashMap, VecDeque};

#[cfg_attr(debug_assertions, derive(Debug))]
#[derive(Clone)]
pub struct DBRule {
  pub rule:       Rule,
  pub nonterm:    DBNonTermKey,
  pub is_scanner: bool,
}

#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct DBTokenData {
  /// The symbol type and precedence.
  pub sym_id:     SymbolId,
  /// The friendly name of this token.
  pub name:       IString,
  /// The scanner non-terminal id of this token.
  pub nonterm_id: DBNonTermKey,
  /// The id of the symbol when used as a lexer token.
  pub tok_id:     DBTermKey,
}

#[derive(Clone, Copy)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct EntryPoint {
  pub nonterm_key:        DBNonTermKey,
  /// The GUID name of the non-terminal.
  pub nonterm_name:       IString,
  /// The GUID name of the non-terminal's entry state.
  pub nonterm_entry_name: IString,
  /// The GUID name of the non-terminal's exit state.
  pub nonterm_exit_name:  IString,
  /// The friendly name of the non-terminal as specified in the
  /// `IMPORT <nonterm> as <entry_name>` preamble.
  pub entry_name:         IString,
  ///
  pub export_id:          usize,
}

/// Data used for the compilation of parse states. contains
/// additional metadata for compilation of LLVM and Bytecode
/// parsers.
#[derive(Clone, Default)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct ParserDatabase {
  /// The name of the parser as defined by the `NAME <name>` preamble in
  /// the root grammar, or by the filename stem in the path for the root
  /// grammar.
  pub name: IString,
  ////
  follow_items: Array<Option<Array<(DBRuleKey, u32, bool)>>>,
  /// Table of symbols.
  nonterm_symbols: Array<SymbolId>,
  /// Table of non-terminal names for public non-terminal.
  ///
  /// - First tuple member: GUID name,
  /// - Second member: friendly name.
  ///
  /// This is a 1-to-1 mapping of all non-terminal indices, so non-terminals
  /// that are scanner or are sub-non-terminals map to empty strings.
  nonterm_names: Array<(IString, IString)>,
  /// Table mapping non-terminal indices to rule indices.
  nonterm_nterm_rules: Array<Array<DBRuleKey>>,
  /// Table of all rules within the grammar and the non-terminal they reduce
  /// to.
  rules: Array<DBRule>,
  /// Table of all tokens generated by the scanners.
  tokens: Array<DBTokenData>,
  /// The entry point non-terminals of the grammar.
  entry_points: Array<EntryPoint>,
  /// The global string store
  string_store: IStringStore,
  /// Custom states that should be integrated into the final parsers
  custom_states: Array<Option<Box<parser::State>>>,
  /// True if the database represents a valid set of rules. This may not be
  /// the case if, for example, the database is comprised of rules that
  /// reference non-extant non-terminals.
  valid: bool,
  /// All items that follow a non-terminal
  follow_db_items: Array<Array<(DBRuleKey, u16)>>,
}

impl ParserDatabase {
  pub fn new(
    name: IString,
    nonterm_symbols: Array<SymbolId>,
    nonterm_names: Array<(IString, IString)>,
    nonterm_nterm_rules: Array<Array<DBRuleKey>>,
    rules: Array<DBRule>,
    tokens: Array<DBTokenData>,
    entry_points: Array<EntryPoint>,
    string_store: IStringStore,
    custom_states: Array<Option<Box<parser::State>>>,
    valid: bool,
  ) -> Self {
    let follow_items = construct_follow(&nonterm_symbols, &rules);

    Self {
      name,
      nonterm_symbols,
      nonterm_names,
      nonterm_nterm_rules,
      rules,
      tokens,
      entry_points,
      string_store,
      follow_items,
      custom_states,
      valid,
      follow_db_items: Default::default(),
    }
  }

  /// Prints token ids and their friendly names to the console
  #[cfg(debug_assertions)]
  pub fn print_tokens(&self) {
    let token_strings =
      self.tokens.iter().enumerate().map(|(idx, t)| format!("{:>0000}: {}", idx, t.name.to_str(&self.string_store).as_str()));

    println!("{}", token_strings.collect::<Vec<_>>().join("\n"))
  }

  pub fn is_valid(&self) -> bool {
    self.valid
  }

  /// Returns an array of [DBNonTermKey]s of the entry point non-terminals.
  pub fn entry_nterm_keys(&self) -> Array<DBNonTermKey> {
    self.entry_points.iter().map(|k| k.nonterm_key).collect()
  }

  /// Returns an array of [EntryPoint]s of the entry point non-terminals.
  pub fn entry_points(&self) -> Array<&EntryPoint> {
    self.entry_points.iter().map(|k| k).collect()
  }

  /// Returns the number of non-terminals stored in the DB
  pub fn nonterms_len(&self) -> usize {
    self.nonterm_symbols.len()
  }

  /// Returns an ordered array of all non-terminals within the DB
  pub fn nonterms(&self) -> &Array<SymbolId> {
    &self.nonterm_symbols
  }

  /// Given a [DBNonTermKey] returns the SymbolId representing the non-terminal,
  /// or [SymbolId::Undefined] if the id is invalid.
  pub fn nonterm_from_name(&self, name: &str) -> DBNonTermKey {
    let string = name.to_token();
    self
      .nonterm_names
      .iter()
      .enumerate()
      .find_map(|(v, (a, b))| if *a == string || *b == string { Some(v.into()) } else { None })
      .unwrap_or_default()
  }

  pub fn get_entry_offset(&self, entry_name: &str, hash_map: &HashMap<IString, usize>) -> Option<usize> {
    let string = entry_name.to_token();
    self.entry_points().iter().find(|e| e.entry_name == string).and_then(|e| hash_map.get(&e.nonterm_entry_name)).cloned()
  }

  /// Returns the name of the database as a string.
  pub fn name_string(&self) -> String {
    self.name.to_string(&self.string_store)
  }

  /// Given a [DBNonTermKey] returns the SymbolId representing the non-terminal,
  /// or [SymbolId::Undefined] if the id is invalid.
  pub fn nonterm_sym(&self, key: DBNonTermKey) -> SymbolId {
    debug_assert!((key.0 as usize) < self.nonterm_symbols.len(), "Invalid DBNonTermKey received");
    self.nonterm_symbols[key.0 as usize].clone()
  }

  /// Given a [DBNonTermKey] returns an IString comprising the name of the
  /// non-terminal, or an empty string if the id is invalid.
  pub fn nonterm_guid_name(&self, key: DBNonTermKey) -> IString {
    self.nonterm_names.get(key.0 as usize).cloned().map(|(n, _)| n).unwrap_or_default()
  }

  /// Given a [DBNonTermKey] returns a [GuardedStr] of the non-terminal's name.
  /// Returns an empty string if the key is invalid.
  pub fn nonterm_guid_name_string<'a>(&'a self, key: DBNonTermKey) -> String {
    self.nonterm_guid_name(key).to_string(&self.string_store)
  }

  /// Given a [DBNonTermKey] returns an IString comprising the name of the
  /// non-terminal, or an empty string if the id is invalid.
  pub fn nonterm_friendly_name(&self, key: DBNonTermKey) -> IString {
    self.nonterm_names.get(key.0 as usize).cloned().map(|(_, n)| n).unwrap_or_default()
  }

  /// Given a [DBNonTermKey] returns a [GuardedStr] of the non-terminal's name.
  /// Returns an empty string if the key is invalid.
  pub fn nonterm_friendly_name_string<'a>(&'a self, key: DBNonTermKey) -> String {
    self.nonterm_friendly_name(key).to_string(&self.string_store)
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn token(&self, key: DBTermKey) -> DBTokenData {
    debug_assert!((key.0 as usize) < self.tokens.len(), "Invalid DBSymKey received");
    self.tokens[key.0 as usize]
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tokens(&self) -> &Array<DBTokenData> {
    &self.tokens
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tok_val(&self, key: DBTermKey) -> usize {
    #[cfg(debug_assertions)]
    {
      let val = self.token(key).tok_id.0 as usize;
      debug_assert!((key.0 as usize) == val);
      val
    }
    #[cfg(not(debug_assertions))]
    {
      key.0 as usize
    }
  }

  /// Given a [DBSymKey] returns the token identifier representing the symbol,
  pub fn tok_data(&self, key: DBTermKey) -> &DBTokenData {
    self.tokens.get(key.0 as usize).as_ref().unwrap()
  }

  /// Given a [DBTermKey] returns the [DBNonTermKey] representing the scanner
  /// nonterminal for the symbol, or None
  pub fn tok_prod(&self, key: DBTermKey) -> Option<DBNonTermKey> {
    self.tokens.get(key.0 as usize).map(|s| s.nonterm_id)
  }

  /// Given a [DBTermKey] returns the associated [SymbolId]
  pub fn sym(&self, key: DBTermKey) -> SymbolId {
    self.tokens.get(key.0 as usize).map(|s| s.sym_id).unwrap_or_default()
  }

  /// Given a [DBNonTermKey] returns an [Array] of [DBRuleKey], or `None`
  /// if the id is invalid.
  pub fn nonterm_rules(&self, key: DBNonTermKey) -> SherpaResult<&Array<DBRuleKey>> {
    o_to_r(self.nonterm_nterm_rules.get(key.0 as usize), "Could not find rule")
  }

  /// Returns the internal Rules
  pub fn rules(&self) -> &[DBRule] {
    self.rules.as_slice()
  }

  /// Given a [DBRuleKey] returns an [Rule], or `None` if
  /// the id is invalid.
  pub fn rule(&self, key: DBRuleKey) -> &Rule {
    self.rules.get(key.0 as usize).map(|e| &e.rule).unwrap()
  }

  /// Given a [DBRuleKey] returns an [Rule], or `None` if
  /// the id is invalid.
  pub fn custom_state(&self, key: DBNonTermKey) -> Option<&parser::State> {
    self.custom_states.get(key.0 as usize).unwrap().as_deref()
  }

  /// Given a [DBRuleKey] returns the [DBNonTermKey] the rule reduces to.
  pub fn rule_nonterm(&self, key: DBRuleKey) -> DBNonTermKey {
    self.rules.get(key.0 as usize).map(|e| e.nonterm).unwrap_or_default()
  }

  /// Returns a reference to the [IStringStore]
  pub fn string_store(&self) -> &IStringStore {
    &self.string_store
  }

  /// Returns all regular (non token) nonterminals.
  pub fn parser_nonterms<'db>(&'db self) -> Array<DBNonTermKey> {
    self
      .nonterms()
      .iter()
      .enumerate()
      .filter_map(|(i, p)| match p {
        SymbolId::NonTerminal { .. } => Some(DBNonTermKey(i as u32)),
        _ => None,
      })
      .collect()
  }

  pub fn nonterm_follow_items<'db>(&'db self, key: DBNonTermKey) -> Items<'db> {
    let mut nonterm_ids = VecDeque::from_iter(vec![key]);
    let mut seen = Set::new();
    let mut items = Items::new();

    while let Some(id) = nonterm_ids.pop_front() {
      if seen.insert(id) {
        if let Some(follow) = self.follow_items.get(id.0 as usize).unwrap() {
          for (rule, sym_index, is_last) in follow {
            let mut item = Item::from_rule(*rule, self);
            item.sym_index = *sym_index as u16;
            items.push(item);

            if *is_last {
              nonterm_ids.push_front(item.nonterm_index())
            }
          }
        }
      }
    }

    items
  }
}

fn construct_follow(nonterm_symbols: &Vec<SymbolId>, rules: &Vec<DBRule>) -> Vec<Option<Vec<(DBRuleKey, u32, bool)>>> {
  let mut follow_items = Array::new();
  for _ in 0..nonterm_symbols.len() {
    follow_items.push(None);
  }

  // Calculates all follow items for all non-terminals
  for (rule_id, rule) in rules.iter().enumerate() {
    if !rule.rule.symbols.is_empty() {
      let last = rule.rule.symbols.len() - 1;
      for (sym_off, SymbolRef { id: sym, .. }) in rule.rule.symbols.iter().enumerate() {
        match sym {
          SymbolId::DBNonTerminalToken { nonterm_key: nterm_key, .. } if rule.is_scanner => {
            let val = follow_items[nterm_key.0 as usize].get_or_insert(vec![]);
            val.push((rule_id.into(), sym_off as u32, sym_off == last))
          }
          SymbolId::DBNonTerminal { key } => {
            let val = follow_items[key.0 as usize].get_or_insert(vec![]);
            val.push((rule_id.into(), sym_off as u32, sym_off == last))
          }
          _ => {}
        }
      }
    }
  }
  follow_items
}

macro_rules! indexed_id_implementations {
  ($id_type:ty) => {
    impl $id_type {
      pub fn to_string(&self) -> String {
        self.0.to_string()
      }
    }

    impl From<u32> for $id_type {
      fn from(value: u32) -> Self {
        Self(value)
      }
    }

    impl From<usize> for $id_type {
      fn from(value: usize) -> Self {
        Self(value as u32)
      }
    }

    impl Into<usize> for $id_type {
      fn into(self) -> usize {
        self.0 as usize
      }
    }

    impl Default for $id_type {
      fn default() -> Self {
        Self(u32::MAX)
      }
    }
  };
}

/// An opaque key used for the access of a rule in a [CompileDatabase]
#[derive(PartialEq, Eq, PartialOrd, Ord, Hash, Clone, Copy)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct DBRuleKey(u32);
indexed_id_implementations!(DBRuleKey);

/// Used as a lookup key for non-terminal data stored within a
/// [CompileDatabase]
#[derive(PartialEq, Eq, PartialOrd, Ord, Hash, Clone, Copy)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct DBNonTermKey(u32);
indexed_id_implementations!(DBNonTermKey);

impl DBNonTermKey {
  /// Returns the symbol representation of this index.
  pub fn to_sym(&self) -> SymbolId {
    SymbolId::DBNonTerminal { key: *self }
  }

  /// Retrieves the binary / bytecode id of the nonterminal.
  pub fn to_val(&self) -> u32 {
    self.0 as u32
  }
}

/// Used as a lookup key for a symbol data within a
/// [CompileDatabase]
#[derive(PartialEq, Eq, PartialOrd, Ord, Hash, Clone, Copy)]
#[cfg_attr(debug_assertions, derive(Debug))]
pub struct DBTermKey(u32);
indexed_id_implementations!(DBTermKey);

impl DBTermKey {
  pub fn default_sym() -> Self {
    Self(0)
  }

  /// Retrieves the binary / bytecode id of the symbol.
  pub fn to_val(&self, db: &ParserDatabase) -> u32 {
    db.tok_val(*self) as u32
  }

  pub fn to_index(&self) -> usize {
    (self.0) as usize
  }
}
